{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janscharf/PC-T-GAN/blob/main/PC_T_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPl8C2Qt6VH6"
      },
      "source": [
        "#Imports and Downloads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLfTV4nW6Zpk"
      },
      "source": [
        "##Downloads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-1K9zn8zwrU",
        "outputId": "b8b4146a-74f1-4ebf-db9b-0b4d444fff07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting uproot\n",
            "  Downloading uproot-5.2.1-py3-none-any.whl (343 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.8/343.8 kB\u001b[0m \u001b[31m956.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting awkward>=2.4.6 (from uproot)\n",
            "  Downloading awkward-2.5.2-py3-none-any.whl (742 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m742.2/742.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from uproot) (2023.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from uproot) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from uproot) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from uproot) (4.5.0)\n",
            "Collecting awkward-cpp==28 (from awkward>=2.4.6->uproot)\n",
            "  Downloading awkward_cpp-28-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (706 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.4/706.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from awkward>=2.4.6->uproot) (7.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->awkward>=2.4.6->uproot) (3.17.0)\n",
            "Installing collected packages: awkward-cpp, awkward, uproot\n",
            "Successfully installed awkward-2.5.2 awkward-cpp-28 uproot-5.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install uproot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WykKBh086czm"
      },
      "source": [
        "##Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KN3Gb4Lr4t9",
        "outputId": "0d04a4f8-e94f-40ad-dc50-836fe151d74d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "import uproot\n",
        "from tqdm import tqdm\n",
        "drive.mount('/content/gdrive/')\n",
        "sys.path.insert(0, '/content/gdrive/MyDrive/Uni/MA')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6aKhySi6fgG"
      },
      "source": [
        "#Defining Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QawmLPaF6jpI"
      },
      "source": [
        "## Transformer Block Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_wYR4S6sLfk"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_heads, key_dim, embed_dim, ff_dim, dropout_rate=0.1):\n",
        "    \"\"\"\n",
        "    embed_dim must be the same as input.shape[0]\n",
        "    \"\"\"\n",
        "    super(TransformerBlock, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.key_dim = key_dim\n",
        "    self.embed_dim = embed_dim\n",
        "    self.ff_dim = ff_dim\n",
        "    self.dropout_rate = dropout_rate\n",
        "    self.attn = tf.keras.layers.MultiHeadAttention(num_heads, key_dim, output_shape=embed_dim)\n",
        "    self.dropout_1 = tf.keras.layers.Dropout(self.dropout_rate)\n",
        "    self.ln_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.ffn_1 = tf.keras.layers.Dense(self.ff_dim, activation=\"relu\")\n",
        "    self.ffn_2 = tf.keras.layers.Dense(self.embed_dim)\n",
        "    self.dropout_2 = tf.keras.layers.Dropout(self.dropout_rate)\n",
        "    self.ln_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.con = tf.keras.layers.Concatenate()\n",
        "\n",
        "  def call(self, inputs):\n",
        "    print(inputs.shape)\n",
        "    input_shape = tf.shape(inputs)\n",
        "    batch_size = input_shape[0]\n",
        "    seq_len = input_shape[1]\n",
        "    attention_output= self.attn(inputs, inputs)\n",
        "    #attention_output, attention_scores = self.attn(inputs, inputs, return_attention_scores=True)\n",
        "    attention_output = self.dropout_1(attention_output)\n",
        "    #conc = self.con([inputs, attention_output])\n",
        "    out1 = self.ln_1(inputs+attention_output)\n",
        "    ffn_1 = self.ffn_1(out1)\n",
        "    ffn_2 = self.ffn_2(ffn_1)\n",
        "    ffn_output = self.dropout_2(ffn_2)\n",
        "    #conc2 = self.con([out1, ffn_output])\n",
        "    #return (self.ln_2(out1 + ffn_output), attention_scores)\n",
        "    return self.ln_2(out1 + ffn_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz-S3NvC6neR"
      },
      "source": [
        "## Wasserstein-GAN with Gradient Penalty Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKqdtoStV-cO"
      },
      "outputs": [],
      "source": [
        "class WGANGP(tf.keras.models.Model):\n",
        "    def __init__(self, critic, generator, latent_dim, critic_steps, gp_weight, N_amount_dist, N_prob_dist):\n",
        "        super(WGANGP, self).__init__()\n",
        "        self.critic = critic\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "        self.critic_steps = critic_steps\n",
        "        self.gp_weight = gp_weight\n",
        "        self.x_shape = 1024\n",
        "        self.y_shape = 1024\n",
        "        self.z_shape = 24\n",
        "        self.interpolate_im = 0\n",
        "        self.N_amount_dist = N_amount_dist\n",
        "        self.N_prob_dist = N_prob_dist\n",
        "        self.batch_size = 0\n",
        "        self.latent_mean = 0\n",
        "        self.latent_stddev = 1\n",
        "\n",
        "    def compile(self, c_optimizer, g_optimizer):\n",
        "        super(WGANGP, self).compile()\n",
        "        self.c_optimizer = c_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.c_wass_loss_metric = tf.keras.metrics.Mean(name=\"c_wass_loss\")\n",
        "        self.c_gp_metric = tf.keras.metrics.Mean(name=\"c_gp\")\n",
        "        self.c_loss_metric = tf.keras.metrics.Mean(name=\"c_loss\")\n",
        "        self.g_loss_metric = tf.keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.c_loss_metric,\n",
        "            self.c_wass_loss_metric,\n",
        "            self.c_gp_metric,\n",
        "            self.g_loss_metric,\n",
        "        ]\n",
        "\n",
        "    def pc_to_im(self, pc):\n",
        "        im = tf.zeros(shape=(self.x_shape, self.y_shape, self.z_shape))\n",
        "        X = pc[:,0]\n",
        "        Y = pc[:,1]\n",
        "        Z = pc[:,2]\n",
        "        E = pc[:,3]\n",
        "        for i in range(X.shape[0]):\n",
        "          im[X[i], Y[i], Z[i]] = E[i]\n",
        "        return im\n",
        "\n",
        "\n",
        "    def interpolate(self, batch_size, fake_images, real_images):\n",
        "        fim = self.pc_to_im(fake_images[0])\n",
        "        rim = self.pc_to_im(real_images[0])\n",
        "        alpha = tf.random.normal((1,), 0, 1)\n",
        "        iim_list = rim * (1 - alpha) + alpha * fim\n",
        "        tf.expand_dim(iim_list, axis=0)\n",
        "        for i in range(1, batch_size):\n",
        "          fim = self.pc_to_im(fake_images[i])\n",
        "          rim = self.pc_to_im(real_images[i])\n",
        "          alpha = tf.random.normal((1,), 0, 1)\n",
        "          iim = rim * (1 - alpha) + alpha * fim\n",
        "          tf.expand_dim(iim, axis=0)\n",
        "          iim_list = tf.concat([iim_list, iim], axis=0)\n",
        "        self.interpolate_im = iim_list\n",
        "\n",
        "    def im_to_pc_with_yield(self):\n",
        "        for i in range(self.interpolate_im.shape[0]):\n",
        "          im = self.interpolate_im[i]\n",
        "          x_list = []\n",
        "          y_list = []\n",
        "          z_list = []\n",
        "          E_list = []\n",
        "          for x in range(self.x_shape):\n",
        "            for y in range(self.y_shape):\n",
        "              for z in range(self.z_shape):\n",
        "                if im[x,y,z] != 0 :\n",
        "                  x_list.append(x)\n",
        "                  y_list.append(y)\n",
        "                  z_list.append(z)\n",
        "                  E_list.append(im[x,y,z])\n",
        "          x_tensor = tf.convert_to_tensor(x_list)\n",
        "          y_tensor = tf.convert_to_tensor(y_list)\n",
        "          z_tensor = tf.convert_to_tensor(z_list)\n",
        "          E_tensor = tf.convert_to_tensor(E_list)\n",
        "          tf.expand_dims(x_tensor, axis=-1)\n",
        "          tf.expand_dims(y_tensor, axis=-1)\n",
        "          tf.expand_dims(z_tensor, axis=-1)\n",
        "          tf.expand_dims(E_tensor, axis=-1)\n",
        "          pc = tf.concat([x_tensor, y_tensor, z_tensor, E_tensor], axis=-1)\n",
        "          yield pc\n",
        "\n",
        "    def gradient_penalty(self, batch_size, real_images, fake_images):\n",
        "        self.interpolate(batch_size, fake_images, real_images)\n",
        "        interpolated = tf.data.Dataset.from_generator(self.im_to_pc_with_yield, output_types=tf.float32, output_shapes=(None, 4))\n",
        "\n",
        "        with tf.GradientTape() as gp_tape:\n",
        "            gp_tape.watch(interpolated)\n",
        "            pred = self.critic(interpolated, training=True)\n",
        "\n",
        "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
        "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
        "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
        "        return gp\n",
        "\n",
        "\n",
        "    def create_fake_images(self):\n",
        "        i = 0\n",
        "        while i < self.batch_size:\n",
        "          N = np.random.choice(self.N_amount_dist, p=self.N_prob_dist)\n",
        "          fake_im = tf.random.normal(shape=(N, self.latent_dim), mean=self.latent_mean, stddev = self.latent_stddev)\n",
        "          if tf.raw_ops.UniqueV2(x=t3, axis=[0]).shape[0]==N:\n",
        "            i+=1\n",
        "            yield fake_im\n",
        "\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        self.batch_size = tf.shape(real_images)[0]\n",
        "\n",
        "        for i in range(self.critic_steps):\n",
        "            random_latent_vectors = tf.data.Dataset.from_generator(self.create_fake_images, output_types=tf.float32, output_shapes=(None, self.latent_dim))\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                fake_images = self.generator(\n",
        "                    random_latent_vectors, training=True\n",
        "                )\n",
        "                fake_predictions = self.critic(fake_images, training=True)\n",
        "                real_predictions = self.critic(real_images, training=True)\n",
        "\n",
        "                c_wass_loss = tf.reduce_mean(fake_predictions) - tf.reduce_mean(\n",
        "                    real_predictions\n",
        "                )\n",
        "                c_gp = self.gradient_penalty(\n",
        "                    self.batch_size, real_images, fake_images\n",
        "                )\n",
        "                c_loss = c_wass_loss + c_gp * self.gp_weight\n",
        "\n",
        "            c_gradient = tape.gradient(c_loss, self.critic.trainable_variables)\n",
        "            self.c_optimizer.apply_gradients(\n",
        "                zip(c_gradient, self.critic.trainable_variables)\n",
        "            )\n",
        "\n",
        "        random_latent_vectors = tf.data.Dataset.from_generator(self.create_fake_images, output_types=tf.float32, output_shapes=(None, self.latent_dim))\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            fake_images = self.generator(random_latent_vectors, training=True)\n",
        "            fake_predictions = self.critic(fake_images, training=True)\n",
        "            g_loss = -tf.reduce_mean(fake_predictions)\n",
        "\n",
        "        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n",
        "        self.g_optimizer.apply_gradients(\n",
        "            zip(gen_gradient, self.generator.trainable_variables)\n",
        "        )\n",
        "\n",
        "        self.c_loss_metric.update_state(c_loss)\n",
        "        self.c_wass_loss_metric.update_state(c_wass_loss)\n",
        "        self.c_gp_metric.update_state(c_gp)\n",
        "        self.g_loss_metric.update_state(g_loss)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTFlfUKN6xK8"
      },
      "source": [
        "## Dataset Generator Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjQQxhuJy6_s"
      },
      "outputs": [],
      "source": [
        "class one_data_generator():\n",
        "    def __init__(self, root_data_path, batch_size, normalize_data):\n",
        "      self.data = root_data_path\n",
        "      actual_path = self.data + \":CaloOutputWriter/Frames\"\n",
        "      file = uproot.open(actual_path)\n",
        "      self.rows = file[\"row\"].array(library=\"np\")\n",
        "      self.columns = file[\"column\"].array(library=\"np\")\n",
        "      self.lanes = file[\"lane\"].array(library=\"np\")\n",
        "      self.nHits = file[\"nHits\"].array(library=\"np\")\n",
        "      self.layer_shape = 24 #layer\n",
        "      self.col_shape = 1024 #col\n",
        "      self.row_shape = 1024 #row\n",
        "      self.layer_shape_reduced = 6\n",
        "      self.col_shape_reduced = 32\n",
        "      self.row_shape_reduced = 32\n",
        "      self.normalize_data = normalize_data\n",
        "      self.batch_size = batch_size\n",
        "\n",
        "    def test(self):\n",
        "      print(\"Test\")\n",
        "\n",
        "    def change_to_real_coordinates_for_one_event(self, layer, row, col):\n",
        "      \"\"\"\n",
        "  \t  This function changes the lane, row, col to its actual coordinates. It takes lane, row, col as input at ouputs\n",
        "      layer, row, col for one event.\n",
        "      \"\"\"\n",
        "      def lane2layer(lane):\n",
        "        const={40:22,39:22,42:20,41:20,44:18,43:18,46:16,45:16,\n",
        "            48:14,47:14,50:12,49:12,52:10,51:10,54: 8,53: 8,\n",
        "            38: 6,55: 6,36: 4,37: 4,32: 0,35: 0,34: 2,33: 2,\n",
        "            64:23,63:23,66:21,65:21,68:19,67:19,70:17,69:17,\n",
        "            72:15,71:15,74:13,73:13,76:11,75:11,78: 9,77: 9,\n",
        "            62: 7,79: 7,60: 5,61: 5,56: 1,59: 1,58: 3,57: 3}\n",
        "        return const[lane]\n",
        "\n",
        "      def lane2chipid(lane):\n",
        "        const={\n",
        "            40: 0,39: 1,42: 2,41: 3,44: 4,43: 5,46: 6,45: 7,\n",
        "            48: 8,47: 9,50:10,49:11,52:12,51:13,54:14,53:15,\n",
        "            38:16,55:17,36:18,37:19,32:20,35:21,34:22,33:23,\n",
        "            64:24,63:25,66:26,65:27,68:28,67:29,70:30,69:31,\n",
        "            72:32,71:33,74:34,73:35,76:36,75:37,78:38,77:39,\n",
        "            62:40,79:41,60:42,61:43,56:44,59:45,58:46,57:47\n",
        "        }\n",
        "        return const[lane]\n",
        "\n",
        "      def layer2isInv(layerNr):\n",
        "        if layerNr%2==1:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "      def IsLeftChip(lane):\n",
        "        layerNr=lane2layer(lane)\n",
        "        isInv = layer2isInv(layerNr)\n",
        "        chipid= lane2chipid(lane)\n",
        "        if chipid%2 ==1:\n",
        "          isOdd=True\n",
        "        else:\n",
        "          isOdd=False\n",
        "        if isOdd!=isInv:\n",
        "          return True\n",
        "        else:\n",
        "          return False\n",
        "\n",
        "      def checkforsides(lane, row, col):\n",
        "        if not IsLeftChip(lane):\n",
        "            col= 1023-col\n",
        "            row= -row-1+512\n",
        "        else:\n",
        "            row=row+512\n",
        "        layer= lane2layer(lane)\n",
        "        return layer, row, col\n",
        "\n",
        "      for i in range(layer.shape[0]):\n",
        "        layer[i], row[i], col[i]=checkforsides(layer[i], row[i], col[i])\n",
        "      return layer, row, col\n",
        "\n",
        "    def pc_to_im(self, layer, row, col, reduced=False):\n",
        "      \"\"\"\n",
        "      This function turns a point cloud into an image matrix, the size of the image depends if it is reduced or not. The image\n",
        "      has the shape (layer, row, col) and so does the point cloud.\n",
        "      \"\"\"\n",
        "      if not reduced:\n",
        "        im = np.zeros(shape=(self.layer_shape, self.row_shape, self.col_shape))\n",
        "      elif reduced:\n",
        "        im = np.zeros(shape=(self.layer_shape_reduced, self.row_shape_reduced, self.col_shape_reduced))\n",
        "      for i in range(layer.shape[0]):\n",
        "        im[layer[i], row[i], col[i]] = 1    #because no value can be given to at tf tensor\n",
        "      return tf.convert_to_tensor(im)\n",
        "\n",
        "    def im_to_pc(self, image, reduced=False):\n",
        "      \"\"\"\n",
        "      This function turns a image matrix into a point cloud, the size of the image depends if it is reduced or not. The image\n",
        "      has the shape (layer, row, col). It returns the point cloud coordinates of layer, row, col seperatly.\n",
        "      \"\"\"\n",
        "      layer_list = []\n",
        "      row_list = []\n",
        "      col_list = []\n",
        "      if reduced:\n",
        "        layer_shape_ac, row_shape_ac, col_shape_ac = self.layer_shape_reduced, self.row_shape_reduced, self.col_shape_reduced\n",
        "      if not reduced:\n",
        "        layer_shape_ac, row_shape_ac, col_shape_ac = self.layer_shape, self.row_shape, self.col_shape\n",
        "      for x in range(layer_shape_ac):\n",
        "        for y in range(row_shape_ac):\n",
        "          for z in range(col_shape_ac):\n",
        "            if image[x,y,z] != 0 :\n",
        "                  layer_list.append(x)\n",
        "                  row_list.append(y)\n",
        "                  col_list.append(z)\n",
        "        return layer_list, row_list, col_list\n",
        "\n",
        "    def create_reduce_model(self):\n",
        "      \"\"\"\n",
        "      creates the model that reduces the size of the data.\n",
        "      \"\"\"\n",
        "      input = tf.keras.Input(shape=(24, 1024, 1024, 1))\n",
        "      x = tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2))(input)\n",
        "      x = tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
        "      x = tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2))(x)\n",
        "      out = tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2))(x)\n",
        "      reduce_model = tf.keras.Model(inputs=input, outputs=out, name=\"reduce_model\")\n",
        "      return reduce_model\n",
        "\n",
        "\n",
        "    def train_generator(self):\n",
        "      \"\"\"\n",
        "      This function is the generator for the train_dataset which includes the non-reduced data.\n",
        "      \"\"\"\n",
        "      for i in range(self.nHits.shape[0]):\n",
        "        layer, row, col = self.change_to_real_coordinates_for_one_event(self.lanes[i], self.rows[i], self.columns[i])\n",
        "        layer = tf.expand_dims(tf.convert_to_tensor(layer, dtype=tf.int32), axis=-1)\n",
        "        row = tf.expand_dims(tf.convert_to_tensor(row, dtype=tf.int32), axis=-1)\n",
        "        col = tf.expand_dims(tf.convert_to_tensor(col, dtype=tf.int32), axis=-1)\n",
        "        E = tf.expand_dims(tf.ones(shape=(self.nHits[i],), dtype=tf.int32), axis=-1)\n",
        "        if self.normalize_data:\n",
        "          row = row/self.row_shape\n",
        "          col = col/self.col_shape\n",
        "          layer = layer/self.layer_shape\n",
        "          data = tf.concat([layer, row, col, E], axis=-1)\n",
        "        yield data\n",
        "\n",
        "    def train_generator_reduced(self):\n",
        "      \"\"\"\n",
        "      This function is the generator for the train_dataset which consists of the reduced data.\n",
        "      \"\"\"\n",
        "      reduce_model = self.create_reduce_model()\n",
        "      for i in range(self.nHits.shape[0]):\n",
        "        layer, row, col = self.change_to_real_coordinates_for_one_event(self.lanes[i], self.rows[i], self.columns[i])\n",
        "        image = self.pc_to_im(layer, row, col, False)\n",
        "        image = tf.expand_dims(image, axis=-1)\n",
        "        image = tf.expand_dims(image, axis=0)\n",
        "        reduce_image = reduce_model(image)\n",
        "        reduce_image = tf.squeeze(reduce_image)\n",
        "        layre, row, col = self.im_to_pc(reduce_image, True)\n",
        "        layer = tf.expand_dims(tf.convert_to_tensor(layer, dtype=tf.int32), axis=-1)\n",
        "        row = tf.expand_dims(tf.convert_to_tensor(row, dtype=tf.int32), axis=-1)\n",
        "        col = tf.expand_dims(tf.convert_to_tensor(col, dtype=tf.int32), axis=-1)\n",
        "        E = tf.expand_dims(tf.ones(shape=(layer.shape[0],), dtype=tf.int32), axis=-1)\n",
        "        if self.normalize_data:\n",
        "          row = row/self.row_shape_reduced\n",
        "          col = col/self.col_shape_reduced\n",
        "          layer = layer/self.layer_shape_reduced\n",
        "        data = tf.concat([layer, row, col, E], axis=-1)\n",
        "        yield data\n",
        "\n",
        "\n",
        "    def create_train_dataset(self, reduced=False):\n",
        "      \"\"\"\n",
        "      This function creates the train_datasets using either the non-reduced data generator or the reduced data generator.\n",
        "      \"\"\"\n",
        "      if reduced:\n",
        "        dataset = tf.data.Dataset.from_generator(self.train_generator_reduced, output_types=tf.int32, output_shapes=(None, 4))\n",
        "        print(\"The dataset consist of reduced images.\")\n",
        "      else:\n",
        "        dataset = tf.data.Dataset.from_generator(self.train_generator, output_types=tf.int32, output_shapes=(None, 4))\n",
        "        print(\"The dataset consist of original images.\")\n",
        "      #dataset = tf.data.Dataset.from_generator(self.train_generator, output_signature=(tf.RaggedTensorSpec(shape=(None, 4), dtype=tf.int32)))\n",
        "      dataset = dataset.shuffle(40).padded_batch(self.batch_size)#, drop_remainder=True)\n",
        "      return dataset\n",
        "\n",
        "    def N_prob_dist(self):\n",
        "      \"\"\"\n",
        "      This function calculates the probability of a specific amount of hits, based on the ditribution of nHits.\n",
        "      \"\"\"\n",
        "      N_amount_dist, N_prob_dist = np.unique(self.nHits_counted, return_counts=True)\n",
        "      N_prob_dist = N_prob_dist/np.sum(N_prob_dist)\n",
        "      return N_amount_dist, N_prob_dist\n",
        "\n",
        "    def N_prob_dist_reduced(self):\n",
        "      \"\"\"\n",
        "      This function gets the prior calculated probability of a specific amount of hits of the reduced dataset.\n",
        "      \"\"\"\n",
        "      data = np.genfromtxt(\"/content/gdrive/MyDrive/Uni/BA/GNN/GAN/nHits_low_res_distribution_real.csv\", delimiter=\",\")\n",
        "      N_amount_dist, N_prob_dist = data[:,0], data[:,1]\n",
        "      return N_amount_dist, N_prob_dist\n",
        "\n",
        "    def plot_one_example(self, path, title=\"Example Event\", reduced=False):\n",
        "      \"\"\"\n",
        "      This function plots an example point cloud and saves it to path.\n",
        "      \"\"\"\n",
        "      i = 0\n",
        "      layer, row, col = self.change_to_real_coordinates_for_one_event(self.lanes[i], self.rows[i], self.columns[i])\n",
        "      layer_shape_ac, row_shape_ac, col_shape_ac = self.layer_shape, self.row_shape, self.col_shape\n",
        "      if reduced:\n",
        "          reduce_model = self.reduce_model()\n",
        "          image = self.pc_to_im(row, col, layer, False)\n",
        "          image = tf.expand_dims(image, axis=0)\n",
        "          image = tf.expand_dims(image, axis=-1)\n",
        "          reduce_image = reduce_model(image)\n",
        "          reduce_image = tf.squeeze(reduce_image)\n",
        "          layer, row, col = self.im_to_pc(reduce_image, True)\n",
        "          layer, row, col = np.asarray(layer), np.asarray(row), np.asarray(col)\n",
        "          layer_shape_ac, row_shape_ac, col_shape_ac = self.layer_shape_reduced, self.row_shape_reduced, self.col_shape_reduced\n",
        "      subplot3d = plt.subplot(111, projection='3d')\n",
        "      subplot3d.axes.set_xlim3d(left=0, right=col_shape_ac)\n",
        "      subplot3d.axes.set_ylim3d(bottom=0, top=row_shape_ac)\n",
        "      subplot3d.axes.set_zlim3d(bottom=0, top=layer_shape_ac)\n",
        "      subplot3d.set_xlabel('columns', fontweight = 'bold', fontsize=15)\n",
        "      subplot3d.set_ylabel('rows', fontweight = 'bold', fontsize=15)\n",
        "      subplot3d.set_zlabel('layers', fontweight = 'bold', fontsize=15)\n",
        "      my_cmap = plt.get_cmap('hsv')\n",
        "      scatter = subplot3d.scatter(col, row, layer, c=layer, cmap=my_cmap, s=1)\n",
        "      #add colorbar on the left\n",
        "      #cbar = plt.colorbar(scatter, shrink=0.5, aspect=5)\n",
        "      #cbar.set_label('layers', rotation=90, labelpad=15, fontsize=15, fontweight = 'bold')\n",
        "      #subplot3d.set_title(title, fontsize=20)\n",
        "      plt.savefig(path, dpi=300)\n",
        "      print(\"Event \"+ title + \" was plotted and saved to \" + path + \" .\")\n",
        "      plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d8LAynXT1pF"
      },
      "source": [
        "#Test Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9TfAkpk5BUi"
      },
      "outputs": [],
      "source": [
        "gen = one_data_generator(\"/content/gdrive/MyDrive/Uni/MA/gps3_E20_spread0.3GeV_halfBox8mmAir_t25.1_nch50_d5_pixelThr82_noise20_stepLength1.root\", 5, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "wQZXoFK1fqhD",
        "outputId": "eab6a8b7-2425-4270-c65e-cd4830e5aeae"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'one_data_generator' object has no attribute 'reduce_model'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-53e8824b6048>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_one_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/im.png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduced\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-e663c6cf7a26>\u001b[0m in \u001b[0;36mplot_one_example\u001b[0;34m(self, path, title, reduced)\u001b[0m\n\u001b[1;32m    204\u001b[0m       \u001b[0mlayer_shape_ac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_shape_ac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_shape_ac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mreduced\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m           \u001b[0mreduce_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m           \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpc_to_im\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m           \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'one_data_generator' object has no attribute 'reduce_model'"
          ]
        }
      ],
      "source": [
        "gen.plot_one_example(\"/content/im.png\", reduced=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "gM0iPsj9MZgd",
        "outputId": "771280df-4425-47c8-cf85-795915f182b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The dataset consist of original images.\n",
            "[1.]\n",
            "Test\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_dataset = gen.creat_train_dataset(False)\n",
        "N, P = gen.N_prob_dist()\n",
        "plt.plot(N, P)\n",
        "gen.test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "mSpyoeALd3YG",
        "outputId": "ef0acea6-4c7f-48d7-95ab-5b9a8eada425"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(None, None, 4)\n",
            "(None, None, 4)\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None, 4)]         0         \n",
            "                                                                 \n",
            " first (Dense)               (None, None, 4)           20        \n",
            "                                                                 \n",
            " transformer_block (Transfo  (None, None, 4)           522       \n",
            " rmerBlock)                                                      \n",
            "                                                                 \n",
            " last (Dense)                (None, None, 4)           20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 562 (2.20 KB)\n",
            "Trainable params: 562 (2.20 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "(None, None, 4)\n",
            "     13/Unknown - 14s 603ms/step"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-02cb3c7a19c7>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, batch_size=5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2653\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2654\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2655\u001b[0;31m                         \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2656\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m                             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    878\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ffn layer is felxible to input points as it only works on the later layers\n",
        "input = tf.keras.Input(shape=(None, 4), dtype=\"int32\")\n",
        "x = tf.keras.layers.Dense(4, \"relu\", name=\"first\")(input)\n",
        "print(x.shape)\n",
        "x = TransformerBlock(2, 6, 4, 30)(x)\n",
        "output = tf.keras.layers.Dense(4, name=\"last\")(x)\n",
        "model = tf.keras.Model(inputs=input, outputs=output)\n",
        "model.summary()\n",
        "model.predict(train_dataset)#, batch_size=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StrvjuJ0a_t1"
      },
      "outputs": [],
      "source": [
        "t3 = tf.constant([[1,2,3],[4,5,6],[4,5,6]])\n",
        "\n",
        "#print(tf.slice(t3, begin=[0, 0, 0],size=[1, :, :]))\n",
        "print(tf.raw_ops.UniqueV2(x=t3, axis=[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXheBP0cUHuc",
        "outputId": "11212067-078d-4dbb-914a-ea295dd98bff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<_TakeDataset element_spec=TensorSpec(shape=(None, None, 4), dtype=tf.int32, name=None)>\n"
          ]
        }
      ],
      "source": [
        "print(train_dataset.take(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 808
        },
        "id": "WR6T_zn6Hs2m",
        "outputId": "2086a3a3-68d2-4f55-b1c8-67f9661cef61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 1024, 1024, 24,   0         \n",
            "                              1)]                                \n",
            "                                                                 \n",
            " max_pooling3d_18 (MaxPooli  (None, 256, 256, 12, 1)   0         \n",
            " ng3D)                                                           \n",
            "                                                                 \n",
            " max_pooling3d_19 (MaxPooli  (None, 64, 64, 6, 1)      0         \n",
            " ng3D)                                                           \n",
            "                                                                 \n",
            " max_pooling3d_20 (MaxPooli  (None, 32, 32, 6, 1)      0         \n",
            " ng3D)                                                           \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 0 (0.00 Byte)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 122/20000 [07:45<21:04:08,  3.82s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-164edce8290d>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_shape_ac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_shape_ac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m               \u001b[0;32mif\u001b[0m \u001b[0mreduced_im\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                   \u001b[0mx_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                   \u001b[0my_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1130\u001b[0m           \u001b[0marray_ops_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m           \u001b[0marray_ops_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m           array_ops_stack.stack(strides))\n\u001b[0m\u001b[1;32m   1133\u001b[0m       \u001b[0;31m# TODO(mdan): Instead of implicitly casting, it's better to enforce the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       \u001b[0;31m# same dtypes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/array_ops_stack.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0;31m# If the input is a constant list, it can be converted to a constant op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Input list contains non-constant tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m    694\u001b[0m   \u001b[0;31m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m   \u001b[0mpreferred_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreferred_dtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m   return tensor_conversion_registry.convert(\n\u001b[0m\u001b[1;32m    697\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccepted_result_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    333\u001b[0m                                          as_ref=False):\n\u001b[1;32m    334\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;31m# Register the conversion function for the \"unconvertible\" types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[0;32m--> 271\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    272\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    282\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m   const_tensor = ops._create_graph_constant(  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    294\u001b[0m ) -> ops._EagerTensorBase:\n\u001b[1;32m    295\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "input = tf.keras.Input(shape=(1024, 1024, 24, 1))\n",
        "x = tf.keras.layers.MaxPooling3D(pool_size=(4, 4, 2))(input)\n",
        "x = tf.keras.layers.MaxPooling3D(pool_size=(4, 4, 2))(x)\n",
        "out = tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 1))(x)\n",
        "reduce_model = tf.keras.Model(inputs=input, outputs=out)\n",
        "reduce_model.summary()\n",
        "\n",
        "file = uproot.open(\"/content/gdrive/MyDrive/Uni/MA/gps3_E20_spread0.3GeV_halfBox8mmAir_t25.1_nch50_d5_pixelThr82_noise20_stepLength1.root:CaloOutputWriter/Frames\")\n",
        "rows = file[\"row\"].array(library=\"np\")\n",
        "columns = file[\"column\"].array(library=\"np\")\n",
        "lanes = file[\"lane\"].array(library=\"np\")\n",
        "nHits = file[\"nHits\"].array(library=\"np\")\n",
        "nHits_counted = []\n",
        "for i in tqdm(range(nHits.shape[0])):\n",
        "        layer, row, col = gen.change_to_real_coordinates_for_one_event(lanes[i], rows[i], columns[i])\n",
        "        X = row\n",
        "        Y = col\n",
        "        Z = layer\n",
        "        im = np.zeros(shape=(1024, 1024, 24))\n",
        "        for i in range(X.shape[0]):\n",
        "          im[X[i], Y[i], Z[i]] = 1\n",
        "        im = tf.convert_to_tensor(im)\n",
        "        im = tf.expand_dims(im, axis=-1)\n",
        "        im = tf.expand_dims(im, axis=0)\n",
        "        reduced_im = reduce_model(im)\n",
        "        reduced_im = tf.squeeze(reduced_im)\n",
        "        x_list = []\n",
        "        y_list = []\n",
        "        z_list = []\n",
        "        x_shape_ac, y_shape_ac, z_shape_ac = 32, 32, 6\n",
        "        for x in range(x_shape_ac):\n",
        "          for y in range(y_shape_ac):\n",
        "            for z in range(z_shape_ac):\n",
        "              if reduced_im[x,y,z] != 0 :\n",
        "                  x_list.append(x)\n",
        "                  y_list.append(y)\n",
        "                  z_list.append(z)\n",
        "        nHits_counted.append(np.asarray(x_list).shape[0])\n",
        "\n",
        "nHits_counted = np.asarray(nHits_counted)\n",
        "np.savetxt(\"/content/nHits_counted_reduced.txt\", nHits_counted, delimiter=\",\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMz4ilKEVk6ty1bIRo39j1Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}